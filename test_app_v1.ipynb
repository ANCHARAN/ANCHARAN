{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ANCHARAN/ANCHARAN/blob/main/test_app_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "7ktq5LVgZEO1",
        "outputId": "642a9977-c65e-4211-b9c8-f83175110e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.68.0)\n",
            "Collecting google-cloud-aiplatform\n",
            "  Downloading google_cloud_aiplatform-1.69.0-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Collecting google-cloud-storage\n",
            "  Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (24.1)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.12.5)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.6)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.9.2)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Collecting PyMuPDFb==1.24.10 (from pymupdf)\n",
            "  Downloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.32.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (1.6.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.8.30)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.26.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
            "Downloading google_cloud_aiplatform-1.69.0-py2.py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_storage-2.18.2-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, pymupdf, google-cloud-storage, google-cloud-aiplatform\n",
            "\u001b[33m  WARNING: The script pymupdf is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed PyMuPDFb-1.24.10 google-cloud-aiplatform-1.69.0 google-cloud-storage-2.18.2 pymupdf-1.24.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "7abb230ef8b84abc96f99aab296ef01b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "! pip3 install --upgrade --user google-cloud-aiplatform pymupdf google-cloud-storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RbDYDSq2ZIWU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VUb57hIZSBV",
        "outputId": "bcc3684f-8671-4a13-d838-073cca62f945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your project ID is: turnkey-mender-436305-s2\n"
          ]
        }
      ],
      "source": [
        "# Define project information\n",
        "\n",
        "import sys\n",
        "\n",
        "PROJECT_ID = \"turnkey-mender-436305-s2\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "# if not running on Colab, try to get the PROJECT_ID automatically\n",
        "if \"google.colab\" not in sys.modules:\n",
        "    import subprocess\n",
        "\n",
        "    PROJECT_ID = subprocess.check_output(\n",
        "        [\"gcloud\", \"config\", \"get-value\", \"project\"], text=True\n",
        "    ).strip()\n",
        "\n",
        "print(f\"Your project ID is: {PROJECT_ID}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tMn30cxTZlfk"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Initialize Vertex AI\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u1ETx3Z1Znpi"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "from rich import print as rich_print\n",
        "from rich.markdown import Markdown as rich_Markdown\n",
        "from vertexai.generative_models import (\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        "    Image,\n",
        ")\n",
        "from vertexai.language_models import TextEmbeddingModel\n",
        "from vertexai.vision_models import MultiModalEmbeddingModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SvMwSRJJh2rM"
      },
      "outputs": [],
      "source": [
        "# Instantiate text model with appropriate name and version\n",
        "text_model = GenerativeModel(\"gemini-1.0-pro\")  # works with text, code\n",
        "\n",
        "# Multimodal models: Choose based on your performance/cost needs\n",
        "multimodal_model_15 = GenerativeModel(\n",
        "    \"gemini-1.5-pro\"\n",
        ")  # works with text, code, images, video(with or without audio) and audio(mp3) with 1M input context - complex reasoning\n",
        "\n",
        "# Multimodal models: Choose based on your performance/cost needs\n",
        "multimodal_model_15_flash = GenerativeModel(\n",
        "    \"gemini-1.5-flash\"\n",
        ")  # works with text, code, images, video(with or without audio) and audio(mp3) with 1M input context - faster inference\n",
        "\n",
        "multimodal_model_10 = GenerativeModel(\n",
        "    \"gemini-1.0-pro-vision-001\"\n",
        ")  # works with text, code, video(without audio) and images with 16k input context\n",
        "\n",
        "# Load text embedding model from pre-trained source\n",
        "text_embedding_model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")\n",
        "\n",
        "# Load multimodal embedding model from pre-trained source\n",
        "multimodal_embedding_model = MultiModalEmbeddingModel.from_pretrained(\n",
        "    \"multimodalembedding\"\n",
        ")  # works with image, image with caption(~32 words), video, video with caption(~32 words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0nDFE0sbLEG",
        "outputId": "ede908d1-173a-462d-c3f8-bef12edfef4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: gsutil rsync uses hashes when modification time is not available at\n",
            "both the source and destination. Your crcmod installation isn't using the\n",
            "module's C extension, so checksumming will run very slowly. If this is your\n",
            "first rsync since updating gsutil, this rsync can take significantly longer than\n",
            "usual. For help installing the extension, please see \"gsutil help crcmod\".\n",
            "\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "!gsutil -m -q rsync -r gs://github-repo/rag/intro_multimodal_rag/intro_multimodal_rag_v2 .\n",
        "print(\"Download completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "K5QaaalQamon"
      },
      "outputs": [],
      "source": [
        "from multimodal_qa_with_rag_utils import get_document_metadata, set_global_variable\n",
        "\n",
        "set_global_variable(\"text_embedding_model\", text_embedding_model)\n",
        "set_global_variable(\"multimodal_embedding_model\", multimodal_embedding_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TJm1bVbvbQm4"
      },
      "outputs": [],
      "source": [
        "from multimodal_qa_with_rag_utils import (\n",
        "    display_images,\n",
        "    get_answer_from_qa_system,\n",
        "    get_gemini_response,\n",
        "    get_similar_image_from_query,\n",
        "    get_similar_text_from_query,\n",
        "    print_text_to_image_citation,\n",
        "    print_text_to_text_citation,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhCtEat0HWSq",
        "outputId": "f2b080f8-a083-4520-8ddc-cd7153227143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.10/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install flask-ngrok\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "\n",
        "def disable_uniform_bucket_level_access(bucket_name):\n",
        "    \"\"\"Disable uniform bucket-level access for a bucket\"\"\"\n",
        "    # bucket_name = \"my-bucket\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.get_bucket(bucket_name)\n",
        "\n",
        "    bucket.iam_configuration.uniform_bucket_level_access_enabled = False\n",
        "    bucket.patch()\n",
        "\n",
        "    print(\n",
        "        f\"Uniform bucket-level access was disabled for {bucket.name}.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def upload_to_gcs(local_file_path, bucket_name, gcs_path):\n",
        "    storage_client = storage.Client.from_service_account_json('/content/turnkey-mender-436305-s2-82aa049e150e.json')\n",
        "    disable_uniform_bucket_level_access(bucket_name)\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(gcs_path)\n",
        "    blob.upload_from_filename(local_file_path)\n",
        "    # Make file publicly accessible\n",
        "    blob.acl.all().grant_read() # Grant read access to all users\n",
        "    blob.acl.save()\n",
        "    blob.make_public()\n",
        "    return blob.public_url\n"
      ],
      "metadata": {
        "id": "LYJwoOGyqN4Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2r1ujHubZ7Qq"
      },
      "outputs": [],
      "source": [
        "def process_pdf(query):\n",
        "    global text_metadata_df, image_metadata_df, matching_results_text, matching_results_image, images_and_descriptions\n",
        "    print(\"Removing pre-existing images folder...\")\n",
        "    os.system('rm -rf images/')  # Remove old images directory if exists\n",
        "\n",
        "    pdf_folder_path = \"/content\"\n",
        "    bucket_name = 'test_1_0'\n",
        "\n",
        "    # Your custom image description prompt\n",
        "    image_description_prompt = \"\"\"\n",
        "    You are a technical image analysis expert. Your task is to generate concise, accurate descriptions of images extracted from documents like research papers and technical blogs.\n",
        "    Focus on capturing key details, trends, or relationships depicted in the images.\n",
        "    \"\"\"\n",
        "\n",
        "    # Assuming 'get_document_metadata' is your custom function for extracting text and images\n",
        "    text_metadata_df, image_metadata_df = get_document_metadata(\n",
        "        multimodal_model_15,\n",
        "        pdf_folder_path,\n",
        "        image_save_dir=\"images\",  # Directory where images will be saved\n",
        "        image_description_prompt=image_description_prompt,\n",
        "        embedding_size=1408,\n",
        "        add_sleep_after_document=True,\n",
        "        sleep_time_after_document=5,\n",
        "    )\n",
        "\n",
        "    print(\"\\n\\n --- Completed processing. ---\")\n",
        "\n",
        "    # Ensure query is a string\n",
        "    if isinstance(query, dict):\n",
        "        query = query.get(\"query\", \"\")  # Extract the query if it's a dict\n",
        "\n",
        "    # Matching user text query with \"chunk_embedding\" to find relevant chunks.\n",
        "    matching_results_text = get_similar_text_from_query(\n",
        "        query,\n",
        "        text_metadata_df,\n",
        "        column_name=\"text_embedding_chunk\",\n",
        "        top_n=3,\n",
        "        chunk_text=True,\n",
        "    )\n",
        "\n",
        "    # Get the relevant text chunks found across documents based on user query\n",
        "    context = \"\\n\".join([value[\"chunk_text\"] for key, value in matching_results_text.items()])\n",
        "\n",
        "    matching_results_image = get_similar_image_from_query(\n",
        "        text_metadata_df,\n",
        "        image_metadata_df,\n",
        "        query=query,\n",
        "        column_name=\"text_embedding_from_image_description\",  # Use image description text embedding\n",
        "        image_emb=False,  # Use text embedding instead of image embedding\n",
        "        top_n=5,\n",
        "        embedding_size=1408,\n",
        "    )\n",
        "\n",
        "\n",
        "    # Print the matched text citations\n",
        "    print_text_to_text_citation(matching_results_text, print_top=True, chunk_text=True)\n",
        "\n",
        "    # Print the matched image citations\n",
        "    print_text_to_image_citation(matching_results_image, print_top=True)\n",
        "\n",
        "\n",
        "    # Markdown(print_text_to_image_citation(matching_results_image, print_top=True))\n",
        "    print(\"\\n **** Result: ***** \\n\")\n",
        "\n",
        "\n",
        "    # Display the top matching image\n",
        "    display_images(\n",
        "        [image[\"img_path\"] for image in matching_results_image if isinstance(image, dict) and \"img_path\" in image],\n",
        "        resize_ratio=0.3,\n",
        "    )\n",
        "\n",
        "    print(\"\\n **** Results: ***** \\n\")\n",
        "\n",
        "    instruction = f\"\"\"Answer the question and explain results with the given Image:\n",
        "    Question: {query}\n",
        "    Image:\n",
        "    \"\"\"\n",
        "\n",
        "    model_input = [instruction]\n",
        "\n",
        "    # Iterate over available images and add them to model_input\n",
        "    for i in range(min(4, len(matching_results_image))):  # Ensure we only access available images, max 4\n",
        "        model_input.extend([\n",
        "            \"Image:\",\n",
        "            matching_results_image[i][\"image_object\"],\n",
        "            \"Description:\",\n",
        "            matching_results_image[i][\"image_description\"]\n",
        "        ])\n",
        "\n",
        "\n",
        "    images_and_descriptions = []\n",
        "    for key, image in matching_results_image.items(): # Use .items() to iterate through key-value pairs\n",
        "      if not isinstance(image, dict):\n",
        "        print(f\"Item is not a dictionary: {image}\")\n",
        "      elif \"img_path\" not in image:\n",
        "        print(f\"'img_path' key missing: {image}\")\n",
        "      else: # Access 'img_path' only if it's a dictionary and contains the key\n",
        "        local_image_path = image[\"img_path\"]\n",
        "        gcs_image_path = f\"images/{os.path.basename(local_image_path)}\"\n",
        "        img_url = upload_to_gcs(local_image_path, bucket_name, gcs_image_path)  # Upload to GCS\n",
        "        print(img_url)\n",
        "        images_and_descriptions.append({\n",
        "                \"img_url\": img_url,\n",
        "                \"description\": image[\"image_description\"]\n",
        "            })\n",
        "\n",
        "\n",
        "\n",
        "    # Generate Gemini response with streaming output\n",
        "    res1=get_gemini_response(\n",
        "            multimodal_model_15,\n",
        "            model_input=model_input,\n",
        "            stream=True,\n",
        "            safety_settings={HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
        "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
        "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE},\n",
        "            generation_config=GenerationConfig(temperature=1, max_output_tokens=8192),\n",
        "        )\n",
        "\n",
        "    print_text_to_image_citation(matching_results_image, print_top=True)\n",
        "\n",
        "    print(res1)\n",
        "\n",
        "\n",
        "    # Generate final prompt with text and image results\n",
        "    prompt = f\"\"\"Answer the question with the given context. If the specific answer is not in the context, please answer 'I don't know'.\n",
        "    Question: {query}\n",
        "    Context: {context + res1}\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate response with Gemini 1.5 Pro based on combined text and image results\n",
        "    result = get_gemini_response(\n",
        "        multimodal_model_15_flash,\n",
        "        model_input=prompt,\n",
        "        stream=True,\n",
        "        safety_settings={HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
        "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
        "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE},\n",
        "        generation_config=GenerationConfig(temperature=1)\n",
        "    )\n",
        "\n",
        "    print(result)\n",
        "\n",
        "    # return result  # Return the generated result\n",
        "\n",
        "    return {\n",
        "        \"result\": result,\n",
        "        \"images_and_descriptions\": images_and_descriptions\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E8Q6XbwISra",
        "outputId": "3c430fc5-53cf-49ec-b238-7372e1e4de68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "# Install ngrok\n",
        "!pip install pyngrok\n",
        "!ngrok config add-authtoken 2mjuubaIHrkvbM9ZnOfwLFdL02H_3n5EYsCJZh8PQ6R51zZ8U  # Replace with your ngrok auth token\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok flask\n",
        "\n",
        "from flask import Flask, request, jsonify, render_template_string\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(addr='5000')\n",
        "print(\"Ngrok tunnel URL:\", public_url)\n",
        "\n",
        "# Define the HTML template\n",
        "html_template_v8 = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Multimodal RAG System</title>\n",
        "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css\">\n",
        "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/tailwindcss/2.2.19/tailwind.min.css\">\n",
        "    <style>\n",
        "        .loading { animation: spin 1s linear infinite; }\n",
        "        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }\n",
        "        .scroll-area { max-height: 300px; overflow-y: auto; }\n",
        "        .image-container { margin-bottom: 1.5rem; }\n",
        "        .image-description { margin-top: 0.5rem; text-align: center; color: #4B5563; }\n",
        "        .gallery-overlay { position: fixed; top: 0; left: 0; right: 0; bottom: 0; background-color: rgba(0, 0, 0, 0.8); z-index: 50; display: none; justify-content: center; align-items: center; padding: 1rem; }\n",
        "        .gallery-img { max-height: 70vh; object-fit: contain; border-radius: 0.5rem; }\n",
        "    </style>\n",
        "</head>\n",
        "<body class=\"bg-gray-100\">\n",
        "    <div class=\"container mx-auto p-4 max-w-4xl\">\n",
        "        <h1 class=\"text-3xl font-bold mb-8 text-center\">Multimodal RAG System</h1>\n",
        "\n",
        "        <div class=\"bg-white shadow-md rounded-lg mb-8\">\n",
        "            <div class=\"p-4\">\n",
        "                <h2 class=\"text-xl font-semibold\">Upload File</h2>\n",
        "                <form id=\"uploadForm\" class=\"space-y-4\">\n",
        "                    <input type=\"file\" name=\"file\" id=\"fileInput\" required class=\"border p-2 rounded w-full\" />\n",
        "                    <button type=\"submit\" id=\"uploadButton\" class=\"bg-blue-500 text-white p-2 rounded w-full\">\n",
        "                        <span id=\"uploadButtonText\">Upload</span>\n",
        "                    </button>\n",
        "                </form>\n",
        "                <p id=\"uploadMessage\" class=\"mt-2 text-sm text-gray-600\"></p>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"bg-white shadow-md rounded-lg mb-8\">\n",
        "            <div class=\"p-4\">\n",
        "                <h2 class=\"text-xl font-semibold\">Process Query</h2>\n",
        "                <form id=\"queryForm\" class=\"space-y-4\">\n",
        "                    <input type=\"text\" name=\"query\" id=\"queryInput\" placeholder=\"Enter your query\" required class=\"border p-2 rounded w-full\" />\n",
        "                    <button type=\"submit\" id=\"processButton\" class=\"bg-green-500 text-white p-2 rounded w-full\">\n",
        "                        <span id=\"processButtonText\">Process Query</span>\n",
        "                    </button>\n",
        "                </form>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div id=\"resultContainer\" class=\"hidden bg-white shadow-md rounded-lg\">\n",
        "            <div class=\"p-4\">\n",
        "                <h2 class=\"text-xl font-semibold\">Query Results</h2>\n",
        "                <p id=\"queryResultMessage\" class=\"mb-4\"></p>\n",
        "                <div class=\"scroll-area rounded-md border p-4\">\n",
        "                    <p id=\"queryResultText\" class=\"text-gray-700 leading-relaxed\"></p>\n",
        "                </div>\n",
        "\n",
        "                <h3 class=\"text-lg font-semibold mb-4\">Images and Descriptions</h3>\n",
        "                <div id=\"imagesContainer\" class=\"grid grid-cols-2 sm:grid-cols-3 md:grid-cols-3 gap-3\"></div>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <!-- Image Gallery Overlay -->\n",
        "    <div id=\"galleryOverlay\" class=\"gallery-overlay\">\n",
        "        <div class=\"relative w-full max-w-4xl\">\n",
        "            <button id=\"closeGallery\" class=\"absolute top-2 right-2 text-white z-10\">\n",
        "                <i class=\"fas fa-times h-6 w-6\"></i>\n",
        "            </button>\n",
        "            <div class=\"flex items-center justify-between\">\n",
        "                <button id=\"prevImage\" class=\"text-white\">\n",
        "                    <i class=\"fas fa-chevron-left h-8 w-8\"></i>\n",
        "                </button>\n",
        "                <img id=\"selectedImage\" class=\"gallery-img\" src=\"\" alt=\"Selected\" />\n",
        "                <button id=\"nextImage\" class=\"text-white\">\n",
        "                    <i class=\"fas fa-chevron-right h-8 w-8\"></i>\n",
        "                </button>\n",
        "            </div>\n",
        "            <div class=\"scroll-area mt-4 h-24 rounded-md bg-white/10 p-4\">\n",
        "                <p id=\"imageDescription\" class=\"text-white text-sm leading-relaxed\"></p>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        let images = []; // Store images globally\n",
        "        document.getElementById('uploadForm').addEventListener('submit', async function(event) {\n",
        "            event.preventDefault();\n",
        "            const uploadButton = document.getElementById('uploadButton');\n",
        "            const uploadButtonText = document.getElementById('uploadButtonText');\n",
        "            const uploadMessage = document.getElementById('uploadMessage');\n",
        "\n",
        "            uploadButton.disabled = true;\n",
        "            uploadButtonText.innerHTML = '<i class=\"fas fa-spinner fa-spin loading\"></i> Uploading...';\n",
        "\n",
        "            const formData = new FormData(event.target);\n",
        "            try {\n",
        "                const response = await fetch('/upload', {\n",
        "                    method: 'POST',\n",
        "                    body: formData\n",
        "                });\n",
        "                const result = await response.json();\n",
        "                uploadMessage.innerText = result.message;\n",
        "                document.getElementById('processButton').disabled = false;\n",
        "            } catch (error) {\n",
        "                console.error('Error uploading file:', error);\n",
        "                uploadMessage.innerText = 'Error uploading file';\n",
        "            } finally {\n",
        "                uploadButton.disabled = false;\n",
        "                uploadButtonText.innerHTML = 'Upload';\n",
        "            }\n",
        "        });\n",
        "\n",
        "        document.getElementById('queryForm').addEventListener('submit', async function(event) {\n",
        "            event.preventDefault();\n",
        "            const processButton = document.getElementById('processButton');\n",
        "            const processButtonText = document.getElementById('processButtonText');\n",
        "            const queryResultMessage = document.getElementById('queryResultMessage');\n",
        "            const imagesContainer = document.getElementById('imagesContainer');\n",
        "            const resultContainer = document.getElementById('resultContainer');\n",
        "            const queryResultText = document.getElementById('queryResultText');\n",
        "\n",
        "            processButton.disabled = true;\n",
        "            processButtonText.innerHTML = '<i class=\"fas fa-spinner fa-spin loading\"></i> Processing...';\n",
        "\n",
        "            const formData = new FormData(event.target);\n",
        "            try {\n",
        "                const response = await fetch('/process-query', {\n",
        "                    method: 'POST',\n",
        "                    body: formData\n",
        "                });\n",
        "                const result = await response.json();\n",
        "                if (result.error) {\n",
        "                    queryResultMessage.innerText = result.error;\n",
        "                    imagesContainer.innerHTML = '';\n",
        "                } else {\n",
        "                    queryResultMessage.innerText = result.result;\n",
        "\n",
        "                    imagesContainer.innerHTML = '';\n",
        "                    images = result.images_and_descriptions; // Store image data globally\n",
        "                    images.forEach((image, index) => {\n",
        "                        const imageDiv = document.createElement('div');\n",
        "                        imageDiv.className = 'image-container';\n",
        "                        imageDiv.innerHTML = `\n",
        "                            <img src=\"${image.img_url}\" alt=\"Thumbnail ${index + 1}\" class=\"max-w-full h-auto rounded-lg shadow-md cursor-pointer\" onclick=\"openImage(${index})\" />\n",
        "                            <p class=\"image-description\">${image.description}</p>\n",
        "                        `;\n",
        "                        imagesContainer.appendChild(imageDiv);\n",
        "                    });\n",
        "                }\n",
        "                resultContainer.classList.remove('hidden');\n",
        "            } catch (error) {\n",
        "                console.error('Error processing query:', error);\n",
        "                queryResultMessage.innerText = 'An error occurred while processing the query.';\n",
        "                imagesContainer.innerHTML = '';\n",
        "            } finally {\n",
        "                processButton.disabled = false;\n",
        "                processButtonText.innerHTML = 'Process Query';\n",
        "            }\n",
        "        });\n",
        "\n",
        "        // Image gallery functions\n",
        "        let selectedIndex = null;\n",
        "\n",
        "        function openImage(index) {\n",
        "            selectedIndex = index;\n",
        "            document.getElementById('galleryOverlay').style.display = 'flex';\n",
        "            displayImage();\n",
        "        }\n",
        "\n",
        "        function closeImage() {\n",
        "            document.getElementById('galleryOverlay').style.display = 'none';\n",
        "        }\n",
        "\n",
        "        function nextImage() {\n",
        "            selectedIndex = (selectedIndex === null || selectedIndex === images.length - 1) ? 0 : selectedIndex + 1;\n",
        "            displayImage();\n",
        "        }\n",
        "\n",
        "        function prevImage() {\n",
        "            selectedIndex = (selectedIndex === null || selectedIndex === 0) ? images.length - 1 : selectedIndex - 1;\n",
        "            displayImage();\n",
        "        }\n",
        "\n",
        "        function displayImage() {\n",
        "            const selectedImage = document.getElementById('selectedImage');\n",
        "            const imageDescription = document.getElementById('imageDescription');\n",
        "            selectedImage.src = images[selectedIndex].img_url;\n",
        "            imageDescription.innerText = images[selectedIndex].description;\n",
        "        }\n",
        "\n",
        "        // Attach click events for gallery navigation\n",
        "        document.getElementById('closeGallery').addEventListener('click', closeImage);\n",
        "        document.getElementById('nextImage').addEventListener('click', nextImage);\n",
        "        document.getElementById('prevImage').addEventListener('click', prevImage);\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "@app.route('/')\n",
        "def hello():\n",
        "    return \"Hello from Colab!\"\n",
        "\n",
        "# Define route to serve HTML form\n",
        "@app.route('/upload', methods=['GET'])\n",
        "def upload_form():\n",
        "    return render_template_string(html_template_v8)\n",
        "\n",
        "# Define upload route\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_file():\n",
        "    file = request.files['file']\n",
        "    file.save(os.path.join(\"/content\", file.filename))  # Save the file in Colab's /content folder\n",
        "    # extract()  # Ensure this function is defined\n",
        "    return jsonify({\"message\": f\"File {file.filename} uploaded successfully!\"})\n",
        "\n",
        "@app.route('/process-query', methods=['POST'])\n",
        "def process_query():\n",
        "    query = request.form['query']  # Get the query from the form\n",
        "    # Replace this with your actual processing logic\n",
        "    result = process_pdf(query)  # Ensure this function is defined and returns appropriate data\n",
        "    return jsonify(result)\n",
        "\n",
        "# Run the Flask app\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(port=5000)  # Ensure the app runs on port 5000\n"
      ],
      "metadata": {
        "id": "H3pRj8ydVvjj",
        "outputId": "6b0bb390-630d-495f-ed57-7063f061e74f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n",
            "Ngrok tunnel URL: NgrokTunnel: \"https://9021-35-239-110-210.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [02/Oct/2024 17:55:29] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [02/Oct/2024 17:55:29] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [02/Oct/2024 17:55:34] \"GET /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [02/Oct/2024 17:55:44] \"POST /upload HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing pre-existing images folder...\n",
            "\n",
            "\n",
            " Processing the file: --------------------------------- /content/CONTROL_AND_COORDINATION_CL_X.pdf \n",
            "\n",
            "\n",
            "Processing page: 1\n",
            "Processing page: 2\n",
            "Extracting image from page: 2, saved as: images/CONTROL_AND_COORDINATION_CL_X.pdf_image_1_0_30.jpeg\n",
            "Processing page: 3\n",
            "Extracting image from page: 3, saved as: images/CONTROL_AND_COORDINATION_CL_X.pdf_image_2_0_33.jpeg\n",
            "Processing page: 4\n",
            "Processing page: 5\n",
            "Processing page: 6\n",
            "Extracting image from page: 6, saved as: images/CONTROL_AND_COORDINATION_CL_X.pdf_image_5_0_40.jpeg\n",
            "Processing page: 7\n",
            "\n",
            " \n",
            " Sleeping for  5  sec before processing the next document to avoid quota issues. You can disable it: \"add_sleep_after_document = False\"  \n",
            "\n",
            "\n",
            " --- Completed processing. ---\n",
            "\u001b[91mCitation 1: Matched text: \n",
            "\u001b[0m\n",
            "\u001b[94mscore: \u001b[0m 0.62\n",
            "\u001b[94mfile_name: \u001b[0m CONTROL_AND_COORDINATION_CL_X.pdf\n",
            "\u001b[94mpage_number: \u001b[0m 5\n",
            "\u001b[94mchunk_number: \u001b[0m 3\n",
            "\u001b[94mchunk_text: \u001b[0m ing liver glycogen to glucose. \n",
            "2. Rise in blood pressure. \n",
            "3. Accelerate rate and force of Heartbeat. \n",
            "4. Increase in oxygen consumption. \n",
            "5. Erection of hair. \n",
            "6. Dilation of pupil \n",
            "7. Initiates stress response. \n",
            "These hormones prepares individual for Fight, Flight & also Frighten, thus also called 3F hormone. \n",
            "D) PARATHYROID: Secrete PARATHORMONE:- helps in regulation of blood calcium level if it is somehow decreased. \n",
            "E) THYMUS: Secrete THYMOSIN: - helps in differentiation of T-Lymphocytes. PROGESTERON & ESTROGEN:- stimulate \n",
            "Uterine lining for embryo implantation to maintain pregnancy, prepare mammary gland for lactation and inhibits \n",
            "Ovulation. \n",
            "1. RELAXIN: relax pubic symphysis & helps to dilate Uterine Cervix near the end of pregnancy. \n",
            "2. INHIBIN/ ACTIN:- inhibition / Activation of FSH & GnRH production. \n",
            " \n",
            "\n",
            "\u001b[91mCitation 1: Matched image path, page number and page text: \n",
            "\u001b[0m\n",
            "\u001b[94mscore: \u001b[0m 0.53\n",
            "\u001b[94mfile_name: \u001b[0m CONTROL_AND_COORDINATION_CL_X.pdf\n",
            "\u001b[94mpath: \u001b[0m images/CONTROL_AND_COORDINATION_CL_X.pdf_image_5_0_40.jpeg\n",
            "\u001b[94mpage number: \u001b[0m 6\n",
            "\u001b[94mpage text: \u001b[0m Page 6 of 7 \n",
            " \n",
            " \n",
            "COORDINATION IN PLANTS \n",
            "Animals have nervous system for controlling and coordinating the activities of the body. but plants have neither a nervous \n",
            "system nor muscles. So how they respond to stimuli. \n",
            "The plants show two different types of movement- one dependent on growth e.g.- movement of tendrils of climber \n",
            "plants, and the other dependent on growth- e.g.- when we touch the leaves of the chhu-mui (Touch me not) they begin to \n",
            "fold up & drop.  \n",
            " \n",
            "Plants cell change shape by changing the amount of water in them resulting in swelling or shrinking, thereby \n",
            "changes the shapes. \n",
            " \n",
            "The movement of the individual plant part or organs of a plant like shoot , root etc. are due to some external stimuli \n",
            "like light, force of gravity , chemical substances , water etc. \n",
            " \n",
            "The directional growth or movement of the plants organ in response to external stimuli is called Tropic movement. \n",
            "The growth towards the stimulus is +ve Tropism and away from the stimulus is ve Tropism. Tropic movement is classified \n",
            "as follows depending on the type of stimulus causing it: \n",
            "1. PHOTOTROPISM: is movement of a part of the plant in response to the light. \n",
            "2. GEOTROPISM: is the upward or downward growth of shoots & roots in response to the pull of earth or gravity. \n",
            "3. HYDROTROPISM: is the movement of the part of the plant in response to the water. \n",
            "4. Chemotropism: is movement of a part of a plant in response to a chemical stimulus.  \n",
            "If the plant part shows movement or growth towards the chemical, it is called +ve  chemotropism and if the \n",
            "plant part shows movement or growth away from the chemical, it is called -ve chemotropism. \n",
            " \n",
            "e.g. - Growth of pollen tube towards a chemical which is produced by an ovule during the process of fertilization in \n",
            "flower. \n",
            " \n",
            "\n",
            "\u001b[94mimage description: \u001b[0m The image displays the location of endocrine glands in the human body, comparing male (a) and female (b) anatomies. Shared glands like the pineal gland, pituitary gland, thyroid gland, parathyroid glands, thymus, pancreas, and adrenal glands are illustrated in the same relative positions in both figures. The male figure (a) highlights the testes as an endocrine gland, while the female figure (b) highlights the ovaries. \n",
            "\n",
            "\n",
            " **** Result: ***** \n",
            "\n",
            "\n",
            " **** Results: ***** \n",
            "\n",
            "Uniform bucket-level access was disabled for test_1_0.\n",
            "https://storage.googleapis.com/test_1_0/images/CONTROL_AND_COORDINATION_CL_X.pdf_image_5_0_40.jpeg\n",
            "Uniform bucket-level access was disabled for test_1_0.\n",
            "https://storage.googleapis.com/test_1_0/images/CONTROL_AND_COORDINATION_CL_X.pdf_image_2_0_33.jpeg\n",
            "Uniform bucket-level access was disabled for test_1_0.\n",
            "https://storage.googleapis.com/test_1_0/images/CONTROL_AND_COORDINATION_CL_X.pdf_image_1_0_30.jpeg\n",
            "\u001b[91mCitation 1: Matched image path, page number and page text: \n",
            "\u001b[0m\n",
            "\u001b[94mscore: \u001b[0m 0.53\n",
            "\u001b[94mfile_name: \u001b[0m CONTROL_AND_COORDINATION_CL_X.pdf\n",
            "\u001b[94mpath: \u001b[0m images/CONTROL_AND_COORDINATION_CL_X.pdf_image_5_0_40.jpeg\n",
            "\u001b[94mpage number: \u001b[0m 6\n",
            "\u001b[94mpage text: \u001b[0m Page 6 of 7 \n",
            " \n",
            " \n",
            "COORDINATION IN PLANTS \n",
            "Animals have nervous system for controlling and coordinating the activities of the body. but plants have neither a nervous \n",
            "system nor muscles. So how they respond to stimuli. \n",
            "The plants show two different types of movement- one dependent on growth e.g.- movement of tendrils of climber \n",
            "plants, and the other dependent on growth- e.g.- when we touch the leaves of the chhu-mui (Touch me not) they begin to \n",
            "fold up & drop.  \n",
            " \n",
            "Plants cell change shape by changing the amount of water in them resulting in swelling or shrinking, thereby \n",
            "changes the shapes. \n",
            " \n",
            "The movement of the individual plant part or organs of a plant like shoot , root etc. are due to some external stimuli \n",
            "like light, force of gravity , chemical substances , water etc. \n",
            " \n",
            "The directional growth or movement of the plants organ in response to external stimuli is called Tropic movement. \n",
            "The growth towards the stimulus is +ve Tropism and away from the stimulus is ve Tropism. Tropic movement is classified \n",
            "as follows depending on the type of stimulus causing it: \n",
            "1. PHOTOTROPISM: is movement of a part of the plant in response to the light. \n",
            "2. GEOTROPISM: is the upward or downward growth of shoots & roots in response to the pull of earth or gravity. \n",
            "3. HYDROTROPISM: is the movement of the part of the plant in response to the water. \n",
            "4. Chemotropism: is movement of a part of a plant in response to a chemical stimulus.  \n",
            "If the plant part shows movement or growth towards the chemical, it is called +ve  chemotropism and if the \n",
            "plant part shows movement or growth away from the chemical, it is called -ve chemotropism. \n",
            " \n",
            "e.g. - Growth of pollen tube towards a chemical which is produced by an ovule during the process of fertilization in \n",
            "flower. \n",
            " \n",
            "\n",
            "\u001b[94mimage description: \u001b[0m The image displays the location of endocrine glands in the human body, comparing male (a) and female (b) anatomies. Shared glands like the pineal gland, pituitary gland, thyroid gland, parathyroid glands, thymus, pancreas, and adrenal glands are illustrated in the same relative positions in both figures. The male figure (a) highlights the testes as an endocrine gland, while the female figure (b) highlights the ovaries. \n",
            "\n",
            "The images you've provided primarily illustrate the nervous system and its components, not the endocrine system and hormones. \n",
            "\n",
            "Let me answer your question about hormones:\n",
            "\n",
            "**What are hormones?**\n",
            "\n",
            "Hormones are **chemical messengers** produced by **endocrine glands** in the body. They are secreted directly into the bloodstream and travel to target cells or organs, where they exert specific effects. \n",
            "\n",
            "Think of hormones like long-distance messengers that regulate various bodily functions, including:\n",
            "\n",
            "* **Growth and development:**  Hormones like growth hormone influence height, bone development, and overall growth.\n",
            "* **Metabolism:** Hormones like insulin and glucagon regulate blood sugar levels.\n",
            "* **Reproduction:** Hormones like estrogen, progesterone, and testosterone control sexual development, menstrual cycles, and sperm production.\n",
            "* **Mood:** Hormones like serotonin and dopamine impact mood, sleep, and emotions.\n",
            "* **Stress response:** Hormones like adrenaline and cortisol help the body respond to stress.\n",
            "\n",
            "**Key characteristics of hormones:**\n",
            "\n",
            "* **Specificity:**  Each hormone has a specific shape that fits certain receptors on target cells, ensuring precise action.\n",
            "* **Potency:**  Hormones are effective in very small amounts.\n",
            "* **Regulation:** Hormone production and release are tightly controlled by feedback mechanisms to maintain balance.\n",
            "\n",
            "**The images you provided relate to the nervous system, which works alongside the endocrine system but through different mechanisms:**\n",
            "\n",
            "* **Figure 7.7:** While depicting endocrine glands, it doesn't directly illustrate hormones. It shows the **location of glands** that produce hormones. \n",
            "* **Figure 7.2:** Shows a **reflex arc**, a rapid nervous system response involving neurons and the spinal cord, not hormonal action.\n",
            "* **Figure 7.1:** Depicts the **structure of a neuron** (nervous system cell) and the **neuromuscular junction**, where neurons communicate with muscles. \n",
            "\n",
            "Let me know if you have more questions about hormones or the endocrine system! \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [02/Oct/2024 17:56:36] \"POST /process-query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hormones are chemical messengers produced by endocrine glands in the body. They are secreted directly into the bloodstream and travel to target cells or organs, where they exert specific effects. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzYQfPbzsXNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "604ee615-6950-47a4-a59e-a827b2c7a0ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uniform bucket-level access was disabled for test_1_0.\n",
            "Uniform bucket-level access was disabled for test_1_0.\n",
            "Uniform bucket-level access was disabled for test_1_0.\n",
            "[{'img_url': 'https://storage.googleapis.com/test_1_0/images/CONTROL_AND_COORDINATION_CL_X.pdf_image_5_0_40.jpeg', 'description': 'The illustration depicts the location of endocrine glands in the human body, comparing male (a) and female (b) anatomy.  Shared glands like the pineal gland, pituitary gland, thyroid, parathyroid glands, thymus, pancreas, and adrenal glands are shown in the same relative positions in both figures. The male figure highlights the testes, while the female figure highlights the ovaries. \\n'}, {'img_url': 'https://storage.googleapis.com/test_1_0/images/CONTROL_AND_COORDINATION_CL_X.pdf_image_2_0_33.jpeg', 'description': 'The diagram illustrates the pathway of a reflex arc, a rapid and involuntary response to a stimulus. In this instance, heat or pain receptors in the skin detect a stimulus (e.g., touching a hot pot). \\n\\nThe signal travels via the sensory neuron to the spinal cord (part of the central nervous system). Within the spinal cord, a relay neuron transmits the signal to a motor neuron. The motor neuron then carries the signal to an effector, in this case, a muscle in the arm, causing it to contract and withdraw the hand from the source of the stimulus. \\n\\nNote that while a message about the stimulus is also sent to the brain, the reflex arc allows for a faster response by bypassing conscious thought processing. \\n'}, {'img_url': 'https://storage.googleapis.com/test_1_0/images/CONTROL_AND_COORDINATION_CL_X.pdf_image_1_0_30.jpeg', 'description': '**Figure 7.1** illustrates the structure of a neuron and its interaction with a muscle fiber at the neuromuscular junction.\\n\\n**(a)** A neuron consists of a **cell body** containing the **nucleus**, branching **dendrites** that receive signals, and a long **axon** transmitting signals to the **nerve ending**.\\n\\n**(b)** The **neuromuscular junction** shows the **axon** terminal contacting a **muscle fiber**. The magnified view highlights the presence of **mitochondria** within the muscle fiber and a nearby **capillary** for blood supply. \\n'}]\n"
          ]
        }
      ],
      "source": [
        "#Method for tessting uploading of iamges to cloud\n",
        "# bucket_name='test_1_0'\n",
        "# images_and_descriptions = []\n",
        "# for key, image in matching_results_image.items(): # Use .items() to iterate through key-value pairs\n",
        "#  if not isinstance(image, dict):\n",
        "#     print(f\"Item is not a dictionary: {image}\")\n",
        "#  elif \"img_path\" not in image:\n",
        "#     print(f\"'img_path' key missing: {image}\")\n",
        "#  else: # Access 'img_path' only if it's a dictionary and contains the key\n",
        "#     local_image_path = image[\"img_path\"]\n",
        "#     gcs_image_path = f\"images/{os.path.basename(local_image_path)}\"\n",
        "#     img_url = upload_to_gcs(local_image_path, bucket_name, gcs_image_path)  # Upload to GCS\n",
        "#     images_and_descriptions.append({\n",
        "#                 \"img_url\": img_url,\n",
        "#                 \"description\": image[\"image_description\"]\n",
        "#             })\n",
        "# print(images_and_descriptions)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}